 # Data-Scraping-with-Selenium-Dynamic-Filtering-using-Streamlit
 ## Introduction
* The "Redbus Data Scraping and Filtering with Streamlit Application" aims to revolutionize the transportation industry by providing a comprehensive solution for collecting, analyzing, and visualizing bus travel data. By utilizing Selenium for web scraping, this project automates the extraction of detailed information from Redbus, including bus routes, schedules, prices, and seat availability. By streamlining data collection and providing powerful tools for data-driven decision-making, this project can significantly improve operational efficiency and strategic planning in the transportation industry.

## Domain 
* TRANSPORTATION

## SKILL-TAKEAWAY
* Python scripting
* Selenium
* Data Collection
* Data Management using MySQL
* Streamlit
  
## TECHNOLOGIES COVERED
* Python 3.9.I
* MySQL 8.0
* Streamlit
* Selenium

## APPROACH
1. Data Scraping:
  * Use Selenium to automate the extraction of Redbus data including routes, schedules, prices, and seat availability.
2. Data Storage:
  * Store the scraped data in a SQL database.
3. Streamlit Application:
  * Develop a Streamlit application to display and filter the scraped data.
  * Implement various filters such as bustype, route, price range, star rating, availability.
4. Data Analysis/Filtering using Streamlit:
  * Use SQL queries to retrieve and filter data based on user inputs.
  * Use Streamlit to allow users to interact with and filter the data through the application.


## APPLICATION INFORMATION

## Retrive the Bus Information:
  Selenium is a powerful tool for automating web browsers, which is especially useful for web scraping tasks. If you want to retrieve bus details from RedBus, you can use Selenium to automate the process of searching for buses and extracting the relevant information. This involves interacting with web elements like input fields and buttons, waiting for the page to load, and extracting the desired details from the search results.

 ## Store data in database:
   * The collected bus details data was transformed into pandas dataframes. Before that, a new database and tables were created using the MySQL connector. With the help of MySQL, the data was inserted into the respective tables. The database could be accessed and managed in the MySQL environment.

## web app - streamlit:
   * With the help of Streamlit, you can create an interactive application similar to RedBus by designing a user-friendly interface that allows users to search for bus routes, view available buses, and get details like departure times and prices.

## RESULTS
* Successfully scrape a minimum of 10 Government State Bus Transport data from Redbus website using Selenium. Also include the private bus information for the selected routes.
* Store the data in a structured SQL database.
* Develop an interactive Streamlit application for data filtering.
* Ensure the application is user-friendly and efficient.




 
     

                                
    
